{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f91608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ ƒêang thu th·∫≠p th√¥ng tin d·ª± √°n...\n",
      "‚úÖ Ho√†n th√†nh! Th√¥ng tin ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: project_complete_info.txt\n",
      "üìÅ File size: 256052 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "def collect_project_info(root_path, output_file=\"project_complete_info.txt\"):\n",
    "    \"\"\"\n",
    "    Thu th·∫≠p c·∫•u tr√∫c th∆∞ m·ª•c v√† n·ªôi dung t·∫•t c·∫£ file code\n",
    "    \"\"\"\n",
    "    # C√°c extension file code ph·ªï bi·∫øn\n",
    "    code_extensions = {\n",
    "        '.py', '.js', '.css', '.json', '.xml', '.yml', '.yaml',\n",
    "        '.md', '.txt', '.sql', '.sh', '.bat', '.cfg', '.ini', '.env',\n",
    "        '.jsx', '.ts', '.tsx', '.vue', '.php', '.java', '.cpp', '.c',\n",
    "        '.h', '.cs', '.rb', '.go', '.rs', '.swift', '.kt'\n",
    "    }\n",
    "    \n",
    "    # Th∆∞ m·ª•c v√† file c·∫ßn b·ªè qua\n",
    "    ignore_dirs = {\n",
    "        '__pycache__', '.git', '.vscode', '.idea', 'node_modules', \n",
    "        '.pytest_cache', '.mypy_cache', 'venv', 'env', '.env',\n",
    "        'dist', 'build', '.next', '.nuxt'\n",
    "    }\n",
    "    \n",
    "    ignore_files = {\n",
    "        '.pyc', '.pyo', '.pyd', '.so', '.dll', '.exe', '.log',\n",
    "        '.tmp', '.temp', '.cache', '.DS_Store', 'Thumbs.db'\n",
    "    }\n",
    "    \n",
    "    # TH√äM: Danh s√°ch file c·ª• th·ªÉ c·∫ßn b·ªè qua\n",
    "    ignore_specific_files = {\n",
    "        'employees.json', 'depots.json', 'transport_providers.json'\n",
    "    }\n",
    "    \n",
    "    root_path = Path(root_path)\n",
    "    \n",
    "    # S·ª¨A L·ªñI: ƒê·∫£m b·∫£o output_file l√† string\n",
    "    if isinstance(output_file, Path):\n",
    "        output_file = str(output_file)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        # Header th√¥ng tin\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(\"TH√îNG TIN D·ª∞ √ÅN HO√ÄN CH·ªàNH\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        f.write(f\"Th·ªùi gian t·∫°o: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Th∆∞ m·ª•c g·ªëc: {root_path.absolute()}\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "        \n",
    "        # 1. C·∫•u tr√∫c th∆∞ m·ª•c\n",
    "        f.write(\"üìÅ C·∫§U TR√öC THU M·ª§C\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        write_directory_tree(f, root_path, ignore_dirs, ignore_specific_files)\n",
    "        f.write(\"\\n\\n\")\n",
    "        \n",
    "        # 2. Danh s√°ch t·∫•t c·∫£ file\n",
    "        f.write(\"üìÑ DANH S√ÅCH T·∫§T C·∫¢ FILE\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")\n",
    "        all_files = list_all_files(root_path, ignore_dirs, ignore_files, ignore_specific_files)\n",
    "        for file_path in sorted(all_files):\n",
    "            rel_path = file_path.relative_to(root_path)\n",
    "            file_size = file_path.stat().st_size\n",
    "            f.write(f\"{rel_path} ({file_size} bytes)\\n\")\n",
    "        f.write(f\"\\nT·ªïng c·ªông: {len(all_files)} file\\n\\n\")\n",
    "        \n",
    "        # 3. N·ªôi dung t·∫•t c·∫£ file code\n",
    "        f.write(\"üíª N·ªòI DUNG T·∫§T C·∫¢ FILE CODE\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\")\n",
    "        \n",
    "        code_files = [f for f in all_files if f.suffix.lower() in code_extensions]\n",
    "        \n",
    "        for file_path in sorted(code_files):\n",
    "            rel_path = file_path.relative_to(root_path)\n",
    "            f.write(f\"\\n{'='*60}\\n\")\n",
    "            f.write(f\"FILE: {rel_path}\\n\")\n",
    "            f.write(f\"{'='*60}\\n\")\n",
    "            \n",
    "            try:\n",
    "                # Th·ª≠ ƒë·ªçc v·ªõi UTF-8 tr∆∞·ªõc\n",
    "                content = file_path.read_text(encoding='utf-8')\n",
    "                f.write(content)\n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    # N·∫øu kh√¥ng ƒë∆∞·ª£c th√¨ th·ª≠ v·ªõi encoding kh√°c\n",
    "                    content = file_path.read_text(encoding='latin-1')\n",
    "                    f.write(content)\n",
    "                except Exception as e:\n",
    "                    f.write(f\"[KH√îNG TH·ªÇ ƒê·ªåC FILE: {e}]\\n\")\n",
    "            except Exception as e:\n",
    "                f.write(f\"[L·ªñI ƒê·ªåC FILE: {e}]\\n\")\n",
    "            \n",
    "            f.write(f\"\\n{'='*60}\\n\")\n",
    "        \n",
    "        # 4. Th·ªëng k√™ cu·ªëi\n",
    "        f.write(f\"\\n\\nüìä TH·ªêNG K√ä\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        f.write(f\"T·ªïng s·ªë file: {len(all_files)}\\n\")\n",
    "        f.write(f\"File code: {len(code_files)}\\n\")\n",
    "        f.write(f\"C√°c lo·∫°i file code:\\n\")\n",
    "        \n",
    "        extensions = {}\n",
    "        for file in code_files:\n",
    "            ext = file.suffix.lower()\n",
    "            extensions[ext] = extensions.get(ext, 0) + 1\n",
    "        \n",
    "        for ext, count in sorted(extensions.items()):\n",
    "            f.write(f\"  {ext}: {count} file\\n\")\n",
    "\n",
    "def write_directory_tree(f, path, ignore_dirs, ignore_specific_files, prefix=\"\"):\n",
    "    \"\"\"Vi·∫øt c·∫•u tr√∫c th∆∞ m·ª•c d·∫°ng tree\"\"\"\n",
    "    try:\n",
    "        items = sorted(path.iterdir(), key=lambda x: (x.is_file(), x.name.lower()))\n",
    "        \n",
    "        for i, item in enumerate(items):\n",
    "            if item.name.startswith('.') and item.name not in {'.env', '.gitignore'}:\n",
    "                continue\n",
    "            if item.name in ignore_dirs:\n",
    "                continue\n",
    "            # TH√äM: B·ªè qua file c·ª• th·ªÉ\n",
    "            if item.name in ignore_specific_files:\n",
    "                continue\n",
    "                \n",
    "            is_last = i == len(items) - 1\n",
    "            current_prefix = \"‚îî‚îÄ‚îÄ \" if is_last else \"‚îú‚îÄ‚îÄ \"\n",
    "            \n",
    "            if item.is_dir():\n",
    "                f.write(f\"{prefix}{current_prefix}üìÅ {item.name}/\\n\")\n",
    "                next_prefix = prefix + (\"    \" if is_last else \"‚îÇ   \")\n",
    "                write_directory_tree(f, item, ignore_dirs, ignore_specific_files, next_prefix)\n",
    "            else:\n",
    "                f.write(f\"{prefix}{current_prefix}üìÑ {item.name}\\n\")\n",
    "                \n",
    "    except PermissionError:\n",
    "        f.write(f\"{prefix}[KH√îNG C√ì QUY·ªÄN TRUY C·∫¨P]\\n\")\n",
    "\n",
    "def list_all_files(root_path, ignore_dirs, ignore_files, ignore_specific_files):\n",
    "    \"\"\"L·∫•y danh s√°ch t·∫•t c·∫£ file\"\"\"\n",
    "    all_files = []\n",
    "    \n",
    "    for item in root_path.rglob(\"*\"):\n",
    "        # B·ªè qua th∆∞ m·ª•c ignore\n",
    "        if any(ignore_dir in item.parts for ignore_dir in ignore_dirs):\n",
    "            continue\n",
    "            \n",
    "        # B·ªè qua file ·∫©n (tr·ª´ m·ªôt s·ªë file quan tr·ªçng)\n",
    "        if item.name.startswith('.') and item.name not in {'.env', '.gitignore', '.htaccess'}:\n",
    "            continue\n",
    "            \n",
    "        # B·ªè qua file theo extension\n",
    "        if item.suffix.lower() in ignore_files:\n",
    "            continue\n",
    "        \n",
    "        # TH√äM: B·ªè qua file c·ª• th·ªÉ theo t√™n\n",
    "        if item.name in ignore_specific_files:\n",
    "            continue\n",
    "            \n",
    "        if item.is_file():\n",
    "            all_files.append(item)\n",
    "    \n",
    "    return all_files\n",
    "\n",
    "# S·ª≠ d·ª•ng script\n",
    "if __name__ == \"__main__\":\n",
    "    # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n n√†y th√†nh th∆∞ m·ª•c d·ª± √°n c·ªßa b·∫°n\n",
    "    project_path = \".\"  # Th∆∞ m·ª•c hi·ªán t·∫°i\n",
    "    output_file = \"project_complete_info.txt\"  # ƒê·∫£m b·∫£o l√† string\n",
    "    \n",
    "    print(\"üîÑ ƒêang thu th·∫≠p th√¥ng tin d·ª± √°n...\")\n",
    "    collect_project_info(project_path, output_file)\n",
    "    print(f\"‚úÖ Ho√†n th√†nh! Th√¥ng tin ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {output_file}\")\n",
    "    print(f\"üìÅ File size: {os.path.getsize(output_file)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42eb010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379c46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import json\n",
    "# from datetime import datetime\n",
    "\n",
    "# # C·∫•u h√¨nh App credentials\n",
    "# APP_ID = \"cli_a7fab27260385010\"\n",
    "# APP_SECRET = \"Zg4MVcFfiOu0g09voTcpfd4WGDpA0Ly5\"\n",
    "\n",
    "# # C·∫•u h√¨nh LarkBase\n",
    "# APP_TOKEN = \"Ey3EbVD9vacAHvs8cVvlHxkKg2r\"\n",
    "# TABLE_ID = \"tblHDR4RsHUCS7Aa\"\n",
    "\n",
    "# def get_tenant_access_token(app_id, app_secret):\n",
    "#     \"\"\"\n",
    "#     L·∫•y tenant access token t·ª´ App ID v√† App Secret\n",
    "#     \"\"\"\n",
    "#     url = \"https://open.larksuite.com/open-apis/auth/v3/app_access_token/internal\"\n",
    "    \n",
    "#     headers = {\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "    \n",
    "#     payload = {\n",
    "#         \"app_id\": app_id,\n",
    "#         \"app_secret\": app_secret\n",
    "#     }\n",
    "    \n",
    "#     response = requests.post(url, headers=headers, json=payload)\n",
    "#     result = response.json()\n",
    "    \n",
    "#     if result.get(\"code\") == 0:\n",
    "#         print(\"‚úì L·∫•y token th√†nh c√¥ng!\")\n",
    "#         return result.get(\"app_access_token\")\n",
    "#     else:\n",
    "#         print(f\"‚úó L·ªói khi l·∫•y token: {result}\")\n",
    "#         return None\n",
    "\n",
    "# def filter_records_by_date(access_token, app_token, table_id, date_timestamp):\n",
    "#     \"\"\"\n",
    "#     L·ªçc records theo ng√†y s·ª≠ d·ª•ng filter\n",
    "#     \"\"\"\n",
    "#     url = f\"https://open.larksuite.com/open-apis/bitable/v1/apps/{app_token}/tables/{table_id}/records/search\"\n",
    "    \n",
    "#     headers = {\n",
    "#         \"Authorization\": f\"Bearer {access_token}\",\n",
    "#         \"Content-Type\": \"application/json\"\n",
    "#     }\n",
    "    \n",
    "#     # Filter theo ng√†y v·ªõi operator \"is\"\n",
    "#     filter_condition = {\n",
    "#         \"conditions\": [\n",
    "#             {\n",
    "#                 \"field_name\": \"Date\",  # T√™n field trong LarkBase\n",
    "#                 \"operator\": \"is\",\n",
    "#                 \"value\": [\"ExactDate\", str(date_timestamp)]\n",
    "#             }\n",
    "#         ],\n",
    "#         \"conjunction\": \"and\"\n",
    "#     }\n",
    "    \n",
    "#     payload = {\n",
    "#         \"filter\": filter_condition,\n",
    "#         \"automatic_fields\": False  # C√≥ l·∫•y c√°c field t·ª± ƒë·ªông hay kh√¥ng\n",
    "#     }\n",
    "    \n",
    "#     response = requests.post(url, headers=headers, json=payload)\n",
    "#     result = response.json()\n",
    "    \n",
    "#     return result\n",
    "\n",
    "# def main():\n",
    "#     print(\"=== TEST FILTER NG√ÄY TRONG LARKBASE ===\\n\")\n",
    "    \n",
    "#     # B∆∞·ªõc 1: L·∫•y access token\n",
    "#     print(\"1. ƒêang l·∫•y access token...\")\n",
    "#     access_token = get_tenant_access_token(APP_ID, APP_SECRET)\n",
    "    \n",
    "#     if not access_token:\n",
    "#         print(\"Kh√¥ng th·ªÉ ti·∫øp t·ª•c do l·ªói x√°c th·ª±c!\")\n",
    "#         return\n",
    "    \n",
    "#     print(f\"Access Token: {access_token[:20]}...\\n\")\n",
    "    \n",
    "#     # B∆∞·ªõc 2: Th·ª±c hi·ªán filter\n",
    "#     print(\"2. ƒêang filter records theo ng√†y...\")\n",
    "    \n",
    "#     # Timestamp t·ª´ y√™u c·∫ßu c·ªßa b·∫°n\n",
    "#     date_timestamp = \"1761693696000\"\n",
    "    \n",
    "#     # Chuy·ªÉn timestamp sang ƒë·ªãnh d·∫°ng readable ƒë·ªÉ ki·ªÉm tra\n",
    "#     date_readable = datetime.fromtimestamp(int(date_timestamp) / 1000)\n",
    "#     print(f\"Ng√†y c·∫ßn filter: {date_readable.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "#     # G·ªçi API filter\n",
    "#     result = filter_records_by_date(access_token, APP_TOKEN, TABLE_ID, date_timestamp)\n",
    "    \n",
    "#     # B∆∞·ªõc 3: Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "#     print(\"3. K·∫øt qu·∫£:\")\n",
    "#     print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "    \n",
    "#     if result.get(\"code\") == 0:\n",
    "#         items = result.get(\"data\", {}).get(\"items\", [])\n",
    "#         print(f\"\\n‚úì T√¨m th·∫•y {len(items)} record(s) kh·ªõp v·ªõi ƒëi·ªÅu ki·ªán filter\")\n",
    "        \n",
    "#         # Hi·ªÉn th·ªã chi ti·∫øt c√°c records\n",
    "#         for idx, item in enumerate(items, 1):\n",
    "#             print(f\"\\n--- Record {idx} ---\")\n",
    "#             print(f\"Record ID: {item.get('record_id')}\")\n",
    "#             print(f\"Fields: {json.dumps(item.get('fields'), indent=2, ensure_ascii=False)}\")\n",
    "#     else:\n",
    "#         print(f\"\\n‚úó L·ªói: {result.get('msg')}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39216227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6506b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lark_oapi as lark\n",
    "# from lark_oapi.api.bitable.v1 import *\n",
    "# import json\n",
    "# from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b818d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # App credentials\n",
    "# APP_ID = \"cli_a7fab27260385010\"\n",
    "# APP_SECRET = \"Zg4MVcFfiOu0g09voTcpfd4WGDpA0Ly5\"\n",
    "\n",
    "# # LarkBase configuration\n",
    "# APP_TOKEN = \"Rm9PbvKLeaFFZcsSQpElnRjIgXg\"\n",
    "# TABLE_ID = \"tblJJPUEFhsXHaxY\"\n",
    "\n",
    "# # Timestamps\n",
    "# start_date = datetime(2025, 10, 20, 0, 0, 0)\n",
    "# START_TIMESTAMP = str(int(start_date.timestamp() * 1000))\n",
    "\n",
    "# end_date = datetime(2025, 10, 30, 23, 59, 59)\n",
    "# END_TIMESTAMP = str(int(end_date.timestamp() * 1000))\n",
    "\n",
    "# # T·∫°o client\n",
    "# client = lark.Client.builder() \\\n",
    "#     .app_id(APP_ID) \\\n",
    "#     .app_secret(APP_SECRET) \\\n",
    "#     .log_level(lark.LogLevel.INFO) \\\n",
    "#     .build()\n",
    "\n",
    "# print(\"‚úì Client initialized\")\n",
    "# print(f\"Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "# print(f\"START_TIMESTAMP: {START_TIMESTAMP}\")\n",
    "# print(f\"END_TIMESTAMP: {END_TIMESTAMP}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d364152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=\"*80)\n",
    "# print(\"FETCH ALL RECORDS - AUTOMATIC PAGINATION\")\n",
    "# print(\"=\"*80)\n",
    "\n",
    "# all_records = []\n",
    "# all_record_ids = []\n",
    "# page_token = None\n",
    "# page_count = 0\n",
    "# max_pages = 20  # Safety limit\n",
    "\n",
    "# while page_count < max_pages:\n",
    "#     page_count += 1\n",
    "#     print(f\"\\n--- Page {page_count} ---\")\n",
    "    \n",
    "#     # T·∫°o request builder\n",
    "#     request_builder = SearchAppTableRecordRequest.builder() \\\n",
    "#         .app_token(APP_TOKEN) \\\n",
    "#         .table_id(TABLE_ID) \\\n",
    "#         .page_size(500)\n",
    "    \n",
    "#     # Th√™m page_token n·∫øu c√≥\n",
    "#     if page_token:\n",
    "#         request_builder.page_token(page_token)\n",
    "#         print(f\"Using page_token: {page_token[:50]}...\")\n",
    "#     else:\n",
    "#         print(\"First request (no page_token)\")\n",
    "    \n",
    "#     # Build request v·ªõi filter\n",
    "#     request = request_builder.request_body(\n",
    "#         SearchAppTableRecordRequestBody.builder()\n",
    "#             .filter(FilterInfo.builder()\n",
    "#                 .conjunction(\"and\")\n",
    "#                 .conditions([\n",
    "#                     Condition.builder()\n",
    "#                         .field_name(\"Ng√†y b√†n giao\")\n",
    "#                         .operator(\"isGreater\")\n",
    "#                         .value([\"ExactDate\", START_TIMESTAMP])\n",
    "#                         .build(),\n",
    "#                     Condition.builder()\n",
    "#                         .field_name(\"Ng√†y b√†n giao\")\n",
    "#                         .operator(\"isLess\")\n",
    "#                         .value([\"ExactDate\", END_TIMESTAMP])\n",
    "#                         .build()\n",
    "#                 ])\n",
    "#                 .build())\n",
    "#             .automatic_fields(False)\n",
    "#             .build()\n",
    "#     ).build()\n",
    "    \n",
    "#     # G·ª≠i request\n",
    "#     response = client.bitable.v1.app_table_record.search(request)\n",
    "    \n",
    "#     if not response.success():\n",
    "#         print(f\"‚ùå Error: {response.code} - {response.msg}\")\n",
    "#         break\n",
    "    \n",
    "#     # X·ª≠ l√Ω response\n",
    "#     data = response.data\n",
    "#     items = data.items or []\n",
    "#     has_more = data.has_more\n",
    "#     page_token = data.page_token\n",
    "    \n",
    "#     # L∆∞u records\n",
    "#     current_ids = [item.record_id for item in items]\n",
    "#     all_records.extend(items)\n",
    "#     all_record_ids.extend(current_ids)\n",
    "    \n",
    "#     print(f\"Retrieved: {len(items)} records\")\n",
    "#     print(f\"Total so far: {len(all_records)}\")\n",
    "#     print(f\"has_more: {has_more}\")\n",
    "    \n",
    "#     # D·ª´ng n·∫øu kh√¥ng c√≤n data\n",
    "#     if not has_more or len(items) == 0:\n",
    "#         print(f\"\\n‚úì Completed! No more data.\")\n",
    "#         break\n",
    "\n",
    "# print(\"\\n\" + \"=\"*80)\n",
    "# print(\"FINAL SUMMARY\")\n",
    "# print(\"=\"*80)\n",
    "# print(f\"Total pages: {page_count}\")\n",
    "# print(f\"Total records: {len(all_records)}\")\n",
    "# print(f\"Unique records: {len(set(all_record_ids))}\")\n",
    "# print(f\"Duplicate records: {len(all_record_ids) - len(set(all_record_ids))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c89968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
